{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee63f4f8",
   "metadata": {},
   "source": [
    "## 2.1 Import Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, cv2, time, numpy as np, matplotlib.pyplot as plt, random\n",
    "import base64, json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "158dcccc-905b-4448-8570-94015bc67d19",
   "metadata": {},
   "source": [
    "## 2.2 Check if Endpoint creation is successful and create the predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74487be9-e5dd-4a4c-aed6-75a2e895aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "\n",
    "# Restore the endpoint name stored in the 2_DeployEndpoint.ipynb notebook\n",
    "%store -r ENDPOINT_NAME\n",
    "print(f'Endpoint Name: {ENDPOINT_NAME}')\n",
    "\n",
    "endpoint_created = False\n",
    "while True:\n",
    "    response = sm_client.list_endpoints()\n",
    "    for ep in response['Endpoints']:\n",
    "        print(f\"Endpoint Status = {ep['EndpointStatus']}\")\n",
    "        if ep['EndpointName']==ENDPOINT_NAME and ep['EndpointStatus']=='InService':\n",
    "            endpoint_created = True\n",
    "            break\n",
    "    if endpoint_created:\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83ec72a4",
   "metadata": {},
   "source": [
    "## 2.3 Run Inference and Generate output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0180fcb-ea19-4fc5-80a9-fdaad7f8e8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_start_time = time.time()\n",
    "# Read the image into a numpy  array\n",
    "orig_image = cv2.imread('bus.jpg')\n",
    "\n",
    "# Calculate the parameters for image resizing\n",
    "image_height, image_width, _ = orig_image.shape\n",
    "model_height, model_width = 640, 640\n",
    "x_ratio = image_width/model_width\n",
    "y_ratio = image_height/model_height\n",
    "\n",
    "# Resize the image as numpy array\n",
    "resized_image = cv2.resize(orig_image, (model_height, model_width))\n",
    "# Conver the array into jpeg\n",
    "resized_jpeg = cv2.imencode('.jpg', resized_image)[1]\n",
    "# Serialize the jpg using base 64\n",
    "payload = base64.b64encode(resized_jpeg).decode('utf-8')\n",
    "\n",
    "runtime= boto3.client('runtime.sagemaker')\n",
    "response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n",
    "                                        ContentType='text/csv',\n",
    "                                        Body=payload)\n",
    "response_body = response['Body'].read()\n",
    "result = json.loads(response_body.decode('ascii'))\n",
    "\n",
    "infer_end_time = time.time()\n",
    "\n",
    "\n",
    "print(f\"Inference Time = {infer_end_time - infer_start_time:0.4f} seconds\")\n",
    "\n",
    "if 'boxes' in result:\n",
    "    for idx,(x1,y1,x2,y2,conf,lbl) in enumerate(result['boxes']):\n",
    "        # Draw Bounding Boxes\n",
    "        x1, x2 = int(x_ratio*x1), int(x_ratio*x2)\n",
    "        y1, y2 = int(y_ratio*y1), int(y_ratio*y2)\n",
    "        color = (random.randint(10,255), random.randint(10,255), random.randint(10,255))\n",
    "        cv2.rectangle(orig_image, (x1,y1), (x2,y2), color, 4)\n",
    "        cv2.putText(orig_image, f\"Class: {int(lbl)}\", (x1,y1-40), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "        cv2.putText(orig_image, f\"Conf: {int(conf*100)}\", (x1,y1-10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "        if 'masks' in result:\n",
    "            # Draw Masks\n",
    "            mask = cv2.resize(np.asarray(result['masks'][idx]), dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)\n",
    "            for c in range(3):\n",
    "                orig_image[:,:,c] = np.where(mask>0.5, orig_image[:,:,c]*(0.5)+0.5*color[c], orig_image[:,:,c])\n",
    "\n",
    "if 'probs' in result:\n",
    "    # Find Class\n",
    "    lbl = result['probs'].index(max(result['probs']))\n",
    "    color = (random.randint(10,255), random.randint(10,255), random.randint(10,255))\n",
    "    cv2.putText(orig_image, f\"Class: {int(lbl)}\", (20,20), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "    \n",
    "if 'keypoints' in result:\n",
    "    # Define the colors for the keypoints and lines\n",
    "    keypoint_color = (random.randint(10,255), random.randint(10,255), random.randint(10,255))\n",
    "    line_color = (random.randint(10,255), random.randint(10,255), random.randint(10,255))\n",
    "\n",
    "    # Define the keypoints and the lines to draw\n",
    "    # keypoints = keypoints_array[:, :, :2]  # Ignore the visibility values\n",
    "    lines = [\n",
    "        (0, 1), (0, 2), (1, 3), (2, 4),  # Head\n",
    "        (5, 6), (5, 7), (7, 9), (6, 8), (8, 10),  # Torso\n",
    "        (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)  # Legs\n",
    "    ]\n",
    "\n",
    "    # Draw the keypoints and the lines on the image\n",
    "    for keypoints_instance in result['keypoints']:\n",
    "        # Draw the keypoints\n",
    "        for keypoint in keypoints_instance:\n",
    "            if keypoint[2] == 0:  # If the keypoint is not visible, skip it\n",
    "                continue\n",
    "            cv2.circle(orig_image, (int(x_ratio*keypoint[:2][0]),int(y_ratio*keypoint[:2][1])), radius=5, color=keypoint_color, thickness=-1)\n",
    "\n",
    "        # Draw the lines\n",
    "        for line in lines:\n",
    "            start_keypoint = keypoints_instance[line[0]]\n",
    "            end_keypoint = keypoints_instance[line[1]]\n",
    "            if start_keypoint[2] == 0 or end_keypoint[2] == 0:  # If any of the keypoints is not visible, skip the line\n",
    "                continue\n",
    "            cv2.line(orig_image, (int(x_ratio*start_keypoint[:2][0]),int(y_ratio*start_keypoint[:2][1])),(int(x_ratio*end_keypoint[:2][0]),int(y_ratio*end_keypoint[:2][1])), color=line_color, thickness=2)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f167efa-02b2-434c-ae35-8109154b6df8",
   "metadata": {},
   "source": [
    "## 2.4 Cleanup by removing Endpoint, Endpoint Config and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b6f40-8a02-47ff-b576-806705aeb20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_client.describe_endpoint_config(EndpointConfigName=ENDPOINT_NAME)\n",
    "print(response)\n",
    "endpoint_config_name = response['EndpointConfigName']\n",
    "\n",
    "# Delete Endpoint\n",
    "sm_client.delete_endpoint(EndpointName=ENDPOINT_NAME)\n",
    "\n",
    "# Delete Endpoint Configuration\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "\n",
    "# Delete Model\n",
    "for prod_var in response['ProductionVariants']:\n",
    "    model_name = prod_var['ModelName']\n",
    "    sm_client.delete_model(ModelName=model_name)     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-pipeline",
   "language": "python",
   "name": "data-pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
